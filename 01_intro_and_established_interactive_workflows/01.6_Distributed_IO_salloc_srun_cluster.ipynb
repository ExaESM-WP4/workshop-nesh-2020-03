{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed IO with a larger cluster\n",
    "\n",
    "We'll see that for applications that are limited by IO bandwidth, a wide distribution across compute nodes can be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical preamble \n",
    "\n",
    "Spin up cluster using `salloc` and `srun`as described here: <https://gist.github.com/willirath/772e0de2b6fbe845f77388c3b16390ea>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use\n",
    "```shell\n",
    "salloc -N 50 -n 50 -c 24 -A training2005 --time=00:15:00\n",
    "```\n",
    "And therein (TODO: How to escape env vars in the `srun` calls?)\n",
    "```shell\n",
    "$ conda activate py3_dask\n",
    "$ srun -r0 -n1 -N1 bash -c 'dask-scheduler --scheduler-file scheduler.json --host ${SLURMD_NODENAME}.ib.juwels.fzj.de &> scheduler.log' &\n",
    "$ srun -n49 -N49 --cpus-per-task=96 bash -c 'dask-worker --scheduler-file scheduler.json --nthreads=16 --memory-limit=96GB --local-directory=/tmp/ --host ${SLURMD_NODENAME}.ib.juwels.fzj.de &>> worker.log' &\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.distributed, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(scheduler_file=\"scheduler.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create random data and write them to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import array as darr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = darr.random.normal(\n",
    "    size=(int(2_000_000_000_000 / 8), ),\n",
    "    chunks=(int(1_000_000_000 / 8), )\n",
    ")\n",
    "random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf random_data.zarr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time random_data.to_zarr(\"random_data.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh random_data.zarr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find largest number with disk IO\n",
    "\n",
    "We'll re-read the data and find the maximum on the fly.\n",
    "\n",
    "Note in the Dask dashboard that we don't saturate CPU load.\n",
    "This means we're limited by IO rather than compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = darr.from_zarr(\"random_data.zarr/\")\n",
    "random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time random_data.max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom line\n",
    "\n",
    "For IO bound problems, we'd like to be able to scale horizontally rather than vertically.\n",
    "\n",
    "That's something that could be tackled with the scheduler config (fill all nodes equally vs. keep as many nodes as possible empty)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_dask]",
   "language": "python",
   "name": "conda-env-py3_dask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
