{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask jobqueue example\n",
    "\n",
    "## What is Dask jobqueue? (https://jobqueue.dask.org/)\n",
    "\n",
    "* deploys Dask workers on typical HPC job queueing systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo estimate with multiple Dask batch job workers\n",
    "We define a Dask jobqueue cluster with Dask workers that each have 4 CPUs and 24 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.distributed\n",
    "import dask_jobqueue\n",
    "\n",
    "dask.config.set({'jobqueue.pbs.walltime': None});  # NQS workaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.PBSCluster(\n",
    "\n",
    "    # Dask workers\n",
    "    cores=4, memory='24GB',\n",
    "    processes=1, # workers per job\n",
    "\n",
    "    # PBS job script\n",
    "    queue='cltestque', name='dask-worker',\n",
    "    resource_spec=('elapstim_req=00:45:00,'\n",
    "                   'cpunum_job=4,memsz_job=24gb'),\n",
    "    local_directory='/scratch',\n",
    "    interface='ib0',\n",
    ")\n",
    "\n",
    "client = dask.distributed.Client(cluster)\n",
    "cluster.scale(jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://192.168.31.13:40380</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.31.13:8787/status' target='_blank'>http://192.168.31.13:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.31.13:40380' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a jobqueue cluster?\n",
    "The above is all we need to specify to run the computation on compute node Dask workers. \n",
    "Let's have a look at what's happening in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RequestID       ReqName  UserName Queue     Pri STT S   Memory      CPU   Elapse R H M Jobs\n",
      "--------------- -------- -------- -------- ---- --- - -------- -------- -------- - - - ----\n",
      "362911.nesh-bat dask-wor smomw260 cltestqu    0 QUE -    0.00B     0.00        0 Y Y Y    1 \n"
     ]
    }
   ],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#PBS -N dask-worker\n",
      "#PBS -q cltestque\n",
      "#PBS -l elapstim_req=00:45:00,cpunum_job=4,memsz_job=24gb\n",
      "JOB_ID=${PBS_JOBID%%.*}\n",
      "\n",
      "/sfs/fs6/home-geomar/smomw260/miniconda3/envs/dask-minimal-20191218/bin/python -m distributed.cli.dask_worker tcp://192.168.31.13:40380 --nthreads 4 --memory-limit 24.00GB --name name --nanny --death-timeout 60 --local-directory /scratch --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's scale up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RequestID       ReqName  UserName Queue     Pri STT S   Memory      CPU   Elapse R H M Jobs\n",
      "--------------- -------- -------- -------- ---- --- - -------- -------- -------- - - - ----\n",
      "362911.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  155.09M     7.81      128 Y Y Y    1 \n",
      "362916.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  156.57M     5.41       27 Y Y Y    1 \n",
      "362917.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  164.08M     3.52       28 Y Y Y    1 \n",
      "362918.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  165.37M     3.32       28 Y Y Y    1 \n",
      "362919.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  166.83M     5.07       27 Y Y Y    1 \n",
      "362920.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  163.40M     5.03       27 Y Y Y    1 \n",
      "362921.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  164.27M     4.30       26 Y Y Y    1 \n",
      "362922.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  158.27M     4.12       26 Y Y Y    1 \n"
     ]
    }
   ],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://192.168.31.13:40380</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.31.13:8787/status' target='_blank'>http://192.168.31.13:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>32</li>\n",
       "  <li><b>Memory: </b>192.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.31.13:40380' processes=8 threads=32, memory=192.00 GB>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here everything is the same as with LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, dask.array\n",
    "\n",
    "def calculate_pi(size_in_bytes, number_of_chunks):\n",
    "    \n",
    "    \"\"\"Calculate pi using a Monte Carlo method.\"\"\"\n",
    "    \n",
    "    array_shape = (int(size_in_bytes / 8 / 2), 2) # tuple\n",
    "    chunk_size = (int(array_shape[0] / number_of_chunks), 2) # tuple\n",
    "    \n",
    "    # 2D random positions array using dask.array\n",
    "    xy = dask.array.random.uniform(\n",
    "        low=0.0, high=1.0, size=array_shape,\n",
    "        # specify chunk size, i.e. task number\n",
    "        chunks=chunk_size )\n",
    "  \n",
    "    xy_inside_circle = (xy ** 2).sum(axis=1) < 1 # boolean\n",
    "\n",
    "    pi = 4 * xy_inside_circle.sum() / xy_inside_circle.size\n",
    "    \n",
    "    # start Dask calculation\n",
    "    pi = pi.compute()\n",
    "\n",
    "    print(f\"\\nfrom {xy.nbytes / 1e9} GB randomly chosen positions\")\n",
    "    print(f\"   pi estimate: {pi}\")\n",
    "    print(f\"   pi error: {abs(pi - numpy.pi)}\\n\")\n",
    "    # display(xy)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 10.0 GB randomly chosen positions\n",
      "   pi estimate: 3.1416782848\n",
      "   pi error: 8.56312102071044e-05\n",
      "\n",
      "CPU times: user 224 ms, sys: 22.5 ms, total: 247 ms\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100) # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 100.0 GB randomly chosen positions\n",
      "   pi estimate: 3.14161525952\n",
      "   pi error: 2.2605930206864855e-05\n",
      "\n",
      "CPU times: user 1.26 s, sys: 176 ms, total: 1.44 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=100_000_000_000, number_of_chunks=250) # 100 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 1000.0 GB randomly chosen positions\n",
      "   pi estimate: 3.141586118144\n",
      "   pi error: 6.535445792987815e-06\n",
      "\n",
      "CPU times: user 12.1 s, sys: 978 ms, total: 13.1 s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=1000) # 1 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can scale up the cluster whenever needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RequestID       ReqName  UserName Queue     Pri STT S   Memory      CPU   Elapse R H M Jobs\n",
      "--------------- -------- -------- -------- ---- --- - -------- -------- -------- - - - ----\n",
      "362911.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  271.55M   646.88      408 Y Y Y    1 \n",
      "362916.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  269.12M   652.89      307 Y Y Y    1 \n",
      "362917.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  278.24M   647.01      308 Y Y Y    1 \n",
      "362918.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  275.72M   660.38      308 Y Y Y    1 \n",
      "362919.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  277.25M   648.40      307 Y Y Y    1 \n",
      "362920.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  275.46M   660.81      307 Y Y Y    1 \n",
      "362921.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  275.61M   652.89      306 Y Y Y    1 \n",
      "362922.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  269.23M   652.02      306 Y Y Y    1 \n",
      "362959.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  165.58M     3.95       18 Y Y Y    1 \n",
      "362960.nesh-bat dask-wor smomw260 cltestqu    0 RUN -  162.07M     4.00       17 Y Y Y    1 \n",
      "362961.nesh-bat dask-wor smomw260 cltestqu    0 RUN -    0.00B     0.00       17 Y Y Y    1 \n",
      "362962.nesh-bat dask-wor smomw260 cltestqu    0 RUN -    0.00B     0.00       17 Y Y Y    1 \n",
      "362963.nesh-bat dask-wor smomw260 cltestqu    0 RUN -    0.00B     0.00       17 Y Y Y    1 \n",
      "362964.nesh-bat dask-wor smomw260 cltestqu    0 RUN -    0.00B     0.00       16 Y Y Y    1 \n",
      "362965.nesh-bat dask-wor smomw260 cltestqu    0 RUN -    0.00B     0.00       16 Y Y Y    1 \n",
      "362966.nesh-bat dask-wor smomw260 cltestqu    0 RUN -    0.00B     0.00       16 Y Y Y    1 \n"
     ]
    }
   ],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://192.168.31.13:40380</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.31.13:8787/status' target='_blank'>http://192.168.31.13:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>64</li>\n",
       "  <li><b>Memory: </b>384.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.31.13:40380' processes=16 threads=64, memory=384.00 GB>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 1000.0 GB randomly chosen positions\n",
      "   pi estimate: 3.141599593408\n",
      "   pi error: 6.939818206763704e-06\n",
      "\n",
      "CPU times: user 9.27 s, sys: 652 ms, total: 9.92 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=1000) # 1 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time pi = calculate_pi(size_in_bytes=10_000_000_000_000, number_of_chunks=10000) # 10 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, we could also adaptively scale the jobqueue cluster!\n",
    "\n",
    "Dask jobqueue is able to scale total worker number based on problem size. You can also specify a target duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(\n",
    "    minimum=2, maximum=20,\n",
    "    target_duration=\"60s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100) # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=1000) # 1 TB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dask-minimal-20191218]",
   "language": "python",
   "name": "conda-env-dask-minimal-20191218-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
